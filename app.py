import streamlit as st
import pandas as pd
import google.generativeai as genai

# рзз. рж╕рзЗржЯрж┐ржВрж╕ ржПржмржВ ржПржкрж┐ржЖржЗ ржХрзА (Streamlit Secrets ржерзЗржХрзЗ ржирзЗржмрзЗ)
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except:
    st.error("API Key ржЦрзБржБржЬрзЗ ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯржирж┐! Streamlit Settings-ржП ржПржЯрж┐ ржпрзЛржЧ ржХрж░рзБржиред")

model = genai.GenerativeModel('gemini-1.5-flash')

# рзи. ржмржЗрзЯрзЗрж░ рж▓рж┐рж╕рзНржЯ рж▓рзЛржб ржХрж░рж╛
@st.cache_data
def load_data():
    return pd.read_csv('books.csv')

df = load_data()

# рзй. ржЗржирзНржЯрж╛рж░ржлрзЗрж╕ ржбрж┐ржЬрж╛ржЗржи
st.set_page_config(page_title="ржЗрж╕рж▓рж╛ржорж┐ржХ рж▓рж╛ржЗржмрзНрж░рзЗрж░рж┐ ржмржЯ", page_icon="ЁЯУЪ")
st.title("ЁЯУЪ ржЗрж╕рж▓рж╛ржорж┐ржХ рж▓рж╛ржЗржмрзНрж░рзЗрж░рж┐ ржЪрзНржпрж╛ржЯржмржЯ")
st.markdown("ржЖржкржирж╛рж░ ржкржЫржирзНржжрзЗрж░ ржмржЗрзЯрзЗрж░ ржирж╛ржо рж▓рж┐ржЦрзБржи, ржЖржорж┐ ржбрж╛ржЙржирж▓рзЛржб рж▓рж┐ржВржХ ржЦрзБржБржЬрзЗ ржжрзЗржмред")

# ржЪрзНржпрж╛ржЯ ржЗржиржкрзБржЯ
user_query = st.text_input("ржмржЗрзЯрзЗрж░ ржирж╛ржо ржмрж╛ рж▓рзЗржЦржХрзЗрж░ ржирж╛ржо рж▓рж┐ржЦрзБржи:", placeholder="ржпрзЗржоржи: рждрж╛ржлрж╕рзАрж░рзЗ ржЗржмржирзЗ ржХрж╛рж╕рзАрж░")

if user_query:
    # рж╕рж╛рж░рзНржЪ рж▓ржЬрж┐ржХ (ржирж╛ржорзЗрж░ ржоржзрзНржпрзЗ рж╢ржмрзНржж ржерж╛ржХрж▓рзЗржЗ ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░ржмрзЗ)
    results = df[df['book_name'].str.contains(user_query, case=False, na=False)]
    
    if not results.empty:
        st.success(f"ржЖржкржирж╛рж░ ржЬржирзНржп {len(results)}ржЯрж┐ ржмржЗ ржкрж╛ржУрзЯрж╛ ржЧрзЗржЫрзЗ:")
        for index, row in results.iterrows():
            with st.expander(f"ЁЯУЦ {row['book_name']}"):
                st.write(f"ЁЯФЧ [ржмржЗржЯрж┐ ржбрж╛ржЙржирж▓рзЛржб ржХрж░рждрзЗ ржПржЦрж╛ржирзЗ ржХрзНрж▓рж┐ржХ ржХрж░рзБржи]({row['download_link']})")
    else:
        # ржпржжрж┐ рж▓рж┐рж╕рзНржЯрзЗ ржирж╛ ржкрж╛ржУрзЯрж╛ ржпрж╛рзЯ, рждржмрзЗ Gemini AI ржЙрждрзНрждрж░ ржжрж┐ржмрзЗ
        with st.spinner("ржЦрзЛржБржЬрж╛ рж╣ржЪрзНржЫрзЗ..."):
            prompt = f"ржЗржЙржЬрж╛рж░ '{user_query}' ржирж╛ржорзЗрж░ ржПржХржЯрж┐ ржмржЗ ржЦрзБржБржЬржЫрзЗ ржпрж╛ ржЖржорж╛ржжрзЗрж░ рждрж╛рж▓рж┐ржХрж╛рзЯ ржирзЗржЗред рждрж╛ржХрзЗ ржЦрзБржм рж╕ржВржХрзНрж╖рзЗржкрзЗ ржПржмржВ ржиржорзНрж░ржнрж╛ржмрзЗ ржмрж╛ржВрж▓рж╛рзЯ ржЬрж╛ржирж╛ржУ ржпрзЗ ржПржЗ ржмржЗржЯрж┐ ржмрж░рзНрждржорж╛ржирзЗ ржЖржорж╛ржжрзЗрж░ рж╕ржВржЧрзНрж░рж╣рзЗ ржирзЗржЗред рждржмрзЗ рж╕рзЗ ржЕржирзНржп ржХрзЛржирзЛ ржмржЗрзЯрзЗрж░ ржирж╛ржо рж▓рж┐ржЦрждрзЗ ржкрж╛рж░рзЗред"
            response = model.generate_content(prompt)
            st.info(response.text)

st.divider()
st.caption("Powered by Google Gemini AI | Developed for Islamic Library")
